{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many pages do you want to scrape?1\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "hot_spots = \"Los Angeles\", \"Colorado\", \"Manhattan\", \"Miami\"\n",
    "lst10 = []\n",
    "\n",
    "def gather_urls():\n",
    "    urls = []\n",
    "    listing_tags = []\n",
    "    times = int(input(\"How many pages do you want to scrape?\"))\n",
    "    if times > 1:\n",
    "        for i in range(1,times + 1):\n",
    "            url = f\"https://www.jamesedition.com/real_estate/united-states?order=popular&page={i}\"\n",
    "            html = requests.get(url).content\n",
    "            soup = bs(html)\n",
    "            row = [i for i in soup.select(\"div.je2-search-page__hits\")]\n",
    "            urls += [i[\"href\"] for i in row[0].find_all(href = True)]\n",
    "            listing_tags += [i.text for i in row[0].select(\"div.ListingCard__tags\")]\n",
    "        urls = [i for i in urls if i.startswith(\"/real\")]\n",
    "    else:\n",
    "        url = \"https://www.jamesedition.com/real_estate/united-states?order=popular\"\n",
    "        html = requests.get(url).content\n",
    "        soup = bs(html)\n",
    "        row = [i for i in soup.select(\"div.je2-search-page__hits\")]\n",
    "        urls += [i[\"href\"] for i in row[0].find_all(href = True)]\n",
    "        urls = [i for i in urls if i.startswith(\"/real\")]\n",
    "        listing_tags = [i.text for i in row[0].select(\"div.ListingCard__tags\")]\n",
    "    return urls, listing_tags\n",
    "\n",
    "\n",
    "urls, listingtags = gather_urls()\n",
    "listing_tag = []\n",
    "for i in range(0, len(listingtags)):\n",
    "    listing_tag.append(\" \".join(listingtags[i].split()))\n",
    "print(len(listing_tag))    \n",
    "bedrooms =[] \n",
    "bathrooms = []\n",
    "m2 = []\n",
    "def BBM():\n",
    "    for i in listing_tag:\n",
    "        i = i.split()\n",
    "        try:\n",
    "            \n",
    "            if \"Bedrooms\" in i[1]:\n",
    "                bedrooms.append(i[0] + \" \" + i[1])\n",
    "            elif \"Bedrooms\" in i[3]:\n",
    "                bedrooms.append(i[2] + \" \" + i[3])\n",
    "            elif \"Bedrooms\" in i[5]:\n",
    "                bedrooms.append(i[4] + \" \" + i[5])\n",
    "        except:\n",
    "            bedrooms.append(\" \")\n",
    "                \n",
    "        try:  \n",
    "            if \"Bathrooms\" in i[1]:\n",
    "                bathrooms.append(i[0] + \" \" + i[1])\n",
    "            elif \"Bathrooms\" in i[3]:\n",
    "                bathrooms.append(i[2] + \" \" + i[3])\n",
    "            elif \"Bathrooms\" in i[5]:\n",
    "                bathrooms.append(i[4] + \" \" + i[5])\n",
    "        except:\n",
    "            bathrooms.append(\" \")\n",
    "        try:\n",
    "            \n",
    "            if \"㎡\" in i[1]:\n",
    "                m2.append(i[0] + \" \" + i[1])\n",
    "            elif \"㎡\" in i[3]:\n",
    "                m2.append(i[2] + \" \" + i[3])\n",
    "            elif \"㎡\" in i[5]:\n",
    "                m2.append(i[4] + \" \" + i[5])\n",
    "        except:\n",
    "            m2.append(\" \")\n",
    "    return bedrooms, bathrooms, m2\n",
    "\n",
    "lst1, lst2, lst3 = BBM()\n",
    "def listings_info():\n",
    "    price = []\n",
    "    desc = []\n",
    "    loc = []\n",
    "    for_sale_by = []\n",
    "    states = []\n",
    "    h = 0\n",
    "    for i in urls:\n",
    "        h += 1\n",
    "        if h == 50:\n",
    "            print(\"50 done\")\n",
    "            h = 0\n",
    "        url = f\"https://www.jamesedition.com{i}\"\n",
    "        html = requests.get(url).content\n",
    "        soup = bs(html)\n",
    "        try:\n",
    "            price.append([i.text for i in soup.select(\"span.je2-texts__heading-34\")][0])\n",
    "        except:\n",
    "            price.append(\" \")\n",
    "        try:\n",
    "            states.append([i.text for i in soup.select(\"#page_content > div.je2-listing-page__container.js-listing-page > div.je2-listing-page__right-side > div > div.je2-listing-page__right-side__head > div.je2-breadcrumbs > ol > li:nth-child(3) > a\")][0])\n",
    "        except:\n",
    "            states.appned(\" \")\n",
    "        try:\n",
    "            desc.append([i.text for i in soup.select(\"#page_content > div.je2-listing-page__container.js-listing-page > div.je2-listing-page__right-side > div > div.je2-listing-page__right-side__description > div:nth-child(3)\")][0])\n",
    "        except:\n",
    "            desc.append(\" \")\n",
    "        try:\n",
    "            loc.append([i.text for i in soup.select(\"#page_content > div.je2-listing-page__container.js-listing-page > div.je2-listing-page__right-side > div > div.je2-listing-page__right-side__location > div.je2-texts__regular-16\")][0])\n",
    "        except:\n",
    "            loc.append(\" \")\n",
    "        try:\n",
    "            for_sale_by.append([i.text for i in soup.select(\"#page_content > div.je2-listing-page__container.js-listing-page > div.je2-listing-page__right-side > div > div.je2-listing-page__right-side__details > div.je2-listing-page__right-side__details__office > div > a\")][0])\n",
    "        except:\n",
    "            for_sale_by.append(\" \")\n",
    "    return price, loc, for_sale_by, desc, states\n",
    "price, loc, for_sale_by, desc, states = listings_info()\n",
    "\n",
    "loc2 = []\n",
    "desc2 = []\n",
    "for i in range(0, len(loc)):\n",
    "    loc2.append(\" \".join(loc[i].split()))\n",
    "    desc2.append(\" \".join(desc[i].split()))\n",
    "desc = desc2\n",
    "loc = loc2\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "df = pd.DataFrame([lst1, lst2, lst3, urls, listing_tag, price, loc, states, for_sale_by, desc]).T\n",
    "\n",
    "for i in range(0, len(df[6])):\n",
    "    if \"Los Angeles\" in df[6][i]:\n",
    "        lst10.append(\"Los Angeles\")\n",
    "    elif \"Colorado\" in df[6][i]:\n",
    "        lst10.append(\"Colorado\")\n",
    "    elif \"Manhattan\" in df[6][i]:\n",
    "        lst10.append(\"Manhattan\")\n",
    "    elif \"Miami\" in df[6][i]:\n",
    "        lst10.append(\"Miami\")\n",
    "    else:\n",
    "        lst10.append(\"Not in hot spot\")\n",
    "df[\"hot spot\"] = lst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
